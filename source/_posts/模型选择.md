---
title: 模型选择
date: 2019-05-04 21:19:49
tags: 机器学习
mathjax: true
---
# **模型评估与选择1**

## 经验误差与过拟合

### 错误率

> 分类错误的样本数占样本总数的比例被称作为**错误率**
> 
> 如果在*m*个样本中有*a*个样本分类错误，则错误率*E = a/m*
### 精度

> 分类正确的样本数占样本总数的比例被称为精度
> 
>  一般情况下，精度 = 1 - 错误率

### 误差

> 学习器的实际预测输出与样本的真实输出之间的差异被称为**误差**。
> 其中，学习器在训练集上的误差被称为**训练误差**，而在新样本上的误差被称为**泛化误差**

### 过拟合

> **过拟合**是指为了得到一致假设而使假设变得过度严格。部分情况下，学习器将训练样本学习的“太好了”，导致其将训练样本本身的一些特征当作了所有潜在样本的特征，这种现象被称为**过拟合**。与**过拟合**相对应的是**欠拟合**,即学习器对于训练样本的一些一般性质尚未学习好。
> 有很多导致过拟合的原因，其中最常见的原因是学习能力过于强大，导致学习器将训练样本中一些不太一般的特性都学到了。
> 而欠拟合则是应为学习器学习能力低下造成。
> 一般来说，欠拟合较为容易克服，而过拟合则是机器学习中面临的关键障碍。

> 举一个简单的例子，学习器对带有锯齿的树叶进行训练。
> 出现过拟合情况时，学习器将会认为树叶必须带有锯齿，对于不带有锯齿的树叶其分类结果为将其分类为非树叶，而欠拟合情况将会出现认为绿色的都属树叶，将整棵树都判断为树叶的情况。

## 评估方法

对于一种机器学习方法，一般情况下需要对其进行泛化误差性能评估并且根据其结果进行算法选择。因此，在评估过程中需要一个测试集来对机器学习算法进行性能评估，然后以测试集上的**测试误差**作为**泛化误差**的近似。

对于一个包含*m*个样例*D*,其中$D=\{(\boldsymbol{x_1},y_1),(\boldsymbol{x_2},y_2)...(\boldsymbol{x_m},y_m)\}​$。为了使系统即能通过其进行训练，又能通过其进行测试，一般可以将其划分为训练集和测试集两部分。一些常见的分类方法如下所示：

### 留出法

> 留出法是直接将数据集$D$划分为两个互斥的集合。其中一部分用作训练集$S$,另一部分则用作测试集$T$，即为$D=S\cup T$，且$S\cap T=\emptyset$。在$S$上训练出模型后，用$T$来评估其测试误差。

> 一般情况下，训练集/测试集的划分要尽可能保持数据分布的一致性。避免数据划分过程中引入的额外偏差对最终的结果产生影响。
> 使用留出法一般会遇到一个问题——若训练集$S$中包含大多数样本，那么训练出的模型可能更接近于用数据集$D$训练出的模型，但是由于测试集$T$较小，因此评估结果可能不够精确。但是若令训练集$T$中包含更多样本，那么训练集$S$与$D$差别较大，模型与用$D$训练出的模型可能有较大差别，从而降低了评估结果的保真性。
> 一般情下，常见做法是将$\frac{2}{3}$至$\frac{4}{5}$的样本数量用作训练，其他的用作测试。

### 交叉验证法

> 交叉验证法先将数据集$D$划分为$k$个大小相似的互斥子集，即$D=D_1\cup D_2 ...\cup D_k$，且其中$D_i\cap D_j=\emptyset$，每个子集尽可能保持数据分布的一致性，即从$D$中分层采样得到。
> 然后，每次使用$k-1$个子集的并集作为训练集，余下的子集作为测试集。这样就可以获得$k$组训练/测试数据。从而可以进行$k$次训练和测试，最终返回的结果是这$k$次测试结果的均值。
> 交叉验证法评估结果的稳定性和保真性很大程度上取决于$k$的取值，所以交叉验证法一般情况下被称为**$k$折交叉验证**

### 留一法

> 假定数据集$D$中包含$m$个样本，若在交叉验证法中令$k=m$，则将会得到交叉验证法的一个特例——留一法(Leave-One-Out,LOO)
> 所以每个子集仅仅包含一个样本，因此留一法不会收到随机样本划分方式的影响。
> 另外，由于留一法相对于原始数据集$D$仅仅少了一个样本，因此通过留一法训练得到的模型与$D$得到的模型十分相似，因此其结果往往比较精确。
> 但是，一般情况下，留一法计算量较大，在面对较大的数据集时性能开销可能是难以忍受的。

### 自助法

> 给定包含$m$个样本的数据集$D$，每次从$D$中随机抽取一个样本将其拷贝放入训练集$D'$，然后将其放回$D$中，使该样本在下次采集中仍有可能被采集。此过程执行$m$次后，将会得到一个包含$m$个样本的数据集$D'$。这就是自助采集的结果。
> 这种采集方式将会有一部分样本不会被采集到，其概率大约为：
> $$
> lim_{m\to \infty}(1-\frac{1}{m})^m=\frac{1}{e}=0.368
> $$
> 即约有36.8%的数据将不会被采集。
> 于是我们可以使用$D'$作为训练集，而使用$D$\ $D'$作为测试集。



