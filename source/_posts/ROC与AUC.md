---
title: ROC与AUC
date: 2019-05-06 16:30:46
tags: 机器学习
mathjax: true

---

\# ROC与AUC

很多学习器是为测试样例产生一个实值或者概率预测，然后将其与一个阈值比较，若大于阈值则分类为正例，反之被分类为反例。

实际上，根据这个实值或者预测结果，可以将样例进行排序，最后可能是正例的排在最前面，最不可能是正例的排在最后面。分类过程就是在这个排序过程中设置一个“截断点”，截断点之前的将会被判定为正例，之后的将会被判定为反例。

在不同的任务中，一般“截断点”的设置也不会相同。若系统更加重视查准率，则可以将截断点设置较为靠前；若系统更加重视查全率，则可以将截断点设置较为靠后。

\---

\## ROC

ROC全称是**受试者工作特征曲线**。与P-R曲线类似，在进行机器学习的过程中，每次根据学习器的预测结果对样例进行排序，同时按照顺序对每个样例依次作为正例进行预测。每次计算其**真正例率**以及**假正例率**，分别作为纵轴以及横轴。这就可以得到**ROC**曲线。

其中，真正例率简称(TPR)，其定义为：

$$

TP= \frac{TP}{TP+FN}

$$

假正例率简称FPR，定义为：

$$

FP=\frac{FP}{TN+FP}

$$

ROC图绘制方式如下：

给定$m^+$个正例和$m^-$个反例。根据机器学习预测结果对其进行排序。然后把分类阈值设置为最大，即所有样例均为反例。此时真正例率与假正例率均为0，在坐标(0,0)处标记一个点。然后依次将每个样例划分为正例，设前一个点的标记为$(x,y)$，若当前点为真正例，则对应点的坐标为$(x,y+\frac{1}{m^+})$，反之若当前点为假正例，则对应坐标为$(x+\frac{1}{m^-},y)$。

在学习器性能对比时，若有一个学习器的ROC曲线被另一个完全包住，则可以断言后者的性能优于前者。若曲线存在交叉，则可以对比ROC曲线下的面积，即**AUC**。

直接计算AUC较为复杂，一种AUC的近似估算方式为（近似看作梯形计算）：

$$

AUC=\frac{1}{2}\sum_{i=1}^{m-1}(x_{i+1}-x_i)(y_i+y_{i+1})

$$

AUC考虑的是样本预测的排序质量，与排序误差有着紧密的联系。给定$m^+$个正例和$m^-$个反例。令$D^+$与$D^-$分别表示正例、反例集合。

则损失可以定义为：

$$

\mathcal{l_{rank}}=\frac{1}{m^+m^-}\sum_{\mathbb{x^+}\in D^+}\sum_{\mathbb{x^-}\in D^-}(\mathbb{I}(f(\mathbb x^+)<f(\mathbb x^-))+\frac{1}{2}\mathbb{I}(f(\mathbb{x^+})=(f(\mathbb{x^-})))

$$

对于每一个样例，若正例的预测值小于反例，则记录为一个罚分，否则记录为0.5个罚分。