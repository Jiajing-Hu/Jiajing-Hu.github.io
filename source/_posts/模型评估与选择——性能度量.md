---
title: 模型评估与选择——性能度量
date: 2019-05-05 20:38:55
tags: 机器学习
mathjax: true
---
# 性能度量

对学习器的泛化性能进行评估，不仅需要有效可行的实验方案，而且需要有衡量模型泛化能力的评价标准，这就是**性能度量**。

**性能度量**反映了任务需求，在对比不同模型的能力时，使用不同的性能度量往往会导致不同的评判结果。这意味着模型的好坏在一定程度上是相对的，什么样的模型是好的，什么样的模型是坏的，不仅却决于数据和算法，而且取决于任务需求。

回归任务中最常用的性能度量方式是**均方误差(MSE)**
$$
E(f;D)=\frac{1}{m}\sum_{i=1}^m((f(x_i)-y_i)^2
$$

对于数据分布$D$还概率密度函数$p(·)$则MSE可表示为：
$$
E(f;D)=\int_{x\sim D}(f(x)-y)^2p(x)dx
$$
---
### 错误率与精度

对于样例$D$，分类的精度可以表示为：
$$
E(f;D)=\frac{1}{m}\sum_{i=1}^m\mathbb{I}(f(x_i)\neq y_i)
$$
同理，精度可以定义为：
$$
acc(f;D)=\frac{1}{m}\sum_{i=1}^m\mathbb{I}(f(x_i)=y_i)
\\
=1-E(f;D)
$$

更一般的，根据数据分布$D$以及概率密度函数$p(·)$，错误率与精度可以描述为：
$$
E(f;D)=\int_{x\sim D}\mathbb{I}(f(x)\neq y)p(x)dx
$$
$$
acc(f;D)=\int_{x\sim D}\mathbb{I}(f(x)=y)p(x)dx\\
=1-E(f;D)
$$
---
### 查准率、查全率

对于二分类问题，往往可以将样例根据真实类别与学习预测类别的组合划分为真正例(TP)，真反例(TN)，假正例(FP)，假反例(FN)四种类型。
显然，存在
$$
TP+TN+FP+FN=总样例
$$
分类结果混淆矩阵如下所示：
<table>
    <tr>
        <th rowspan="2">真实情况</th>
        <th colspan="2">预测结果</th>
    </tr>
    <tr>
        <td>正例</td>
        <td>反例</td>
    </tr>
    <tr>
        <td>正例</td>
        <td>TP(真正例)</td>
        <td>FN(假反例)</td>
    </tr>
    <tr>
        <td>反例</td>
        <td>FP(假正例)</td>
        <td>TN(真反例)</td>
    </tr>
</table>

**查准率**$P$与**查全率**$R$分别定义为：
$$
P=\frac{TP}{TP+FP}
$$
$$
R=\frac{TP}{TP+FN}
$$


一般情况下，查准率越高，查全率往往较低。而查全率较高的时候，则查准率较低。

---

### P-R曲线

> 很多时候，我们可以根据学习器的预测结果对样例进行排序。排在前面的是学习器认为最有可能是正例的样本而排在最后的是学习器认为是最不可能是正例的样本。按照顺序逐个把样本作为正例进行预测，则每次可以计算出当前的查全率、查准率，以查全率为横轴，查准率为纵轴则可以得到查准率-查全率曲线，简称P-R曲线。

P-R曲线直观地显示出学习器在样本总体上的查全率、查准率。在进行比较时，若一个学习器的P-R曲线被另一个学习器完全“包住”，则表示后者的性能优于前者。

若P-R曲线发生了交叉，则只能在具体的查全率、查准率下进行比较。
如果此时仍要分别两者的性能优劣，一个比较常用的方法是比较两者P-R曲线下的面积大小。

由于P-R曲线的面积不易计算，另一种比较常用的方法是比较**平衡点(Break-Even Point,BEP)**，它是查全率=查准率时的取值。

由于BEP过于简单，一般情况下更常用的是**F1度量**

$$
F1=\frac{2PR}{P+R}=\frac{2TP}{样例总数+TP-TN}
$$

更一般的，存在$F_\beta$
$$
F_\beta=\frac{(1+\beta^2)PR}{\beta^2P+R}
$$

其中$\beta>0$度量了查全率对查准率的相对重要性。$\beta>1$时查全率更为重要而$\beta<1$时查准率更为重要。

很多时候，样例存在许多二分类混淆矩阵。若相对其整体进行考察查准率与查全率。

一种常见做法是先在各个二分类矩阵中计算出查准率与查全率。记为$(P_1,R_1),(P_2,R_2)...(P_n,R_n)$，然后计算得到其平均值。这样就得到了宏查准率、宏查全率以及宏$F1$
$$
marcoP=\frac{1}{n}\sum_{i=1}^nP_i
$$

$$
marcoR=\frac{1}{n}\sum_{i=1}^nR_i
$$

$$
marcoF1=\frac{2macroP·macroR}{macroP+macroR}
$$

同样的，可以先对每个二分类矩阵的查全率、查准率进行平均后计算得到**微查准率**、**微查全率**以及**微$F1$**

$$
microP=\frac{TP}{TP+FP}
$$

$$
microR=\frac{TP}{TP+FN}
$$

$$
microF1=\frac{2microP·microR}{microP+microR}
$$
